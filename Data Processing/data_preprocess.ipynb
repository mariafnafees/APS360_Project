{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMLkG3JKanan"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import shutil\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UQl40iMbGoh",
        "outputId": "92420e82-0154-476c-b557-5cfd15bbf970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "RAW_DATA_DIR = \"quickdraw_raw\"\n",
        "PROCESSED_DATA_DIR = \"quickdraw_processed\"\n",
        "NEW_DATA_DIR = \"/content/drive/MyDrive/processed_new_data/\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/final_dataset/\"\n",
        "\n",
        "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
        "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
        "os.makedirs(NEW_DATA_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "LL9Nq_bRbL23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selected Quick Draw classes\n",
        "CLASSES = [\"apple\", \"bee\", \"cat\", \"eyeglasses\", \"fish\", \"flower\", \"house\", \"pencil\", \"pizza\"]\n",
        "SAMPLES_PER_CLASS = 500  # Can be adjusted"
      ],
      "metadata": {
        "id": "Wq5evSsbbjna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download and load QuickDraw data\n",
        "def load_quickdraw_class(class_name, num_samples):\n",
        "    url = f\"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{class_name}.npy\"\n",
        "    file_path = os.path.join(RAW_DATA_DIR, f\"{class_name}.npy\")\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        os.system(f\"wget -O {file_path} {url}\")\n",
        "\n",
        "    data = np.load(file_path)\n",
        "    return data[:num_samples]  # Take only the first num_samples\n",
        "\n",
        "# Load QuickDraw dataset\n",
        "quickdraw_data = {}\n",
        "for cls in CLASSES:\n",
        "    quickdraw_data[cls] = load_quickdraw_class(cls, SAMPLES_PER_CLASS)\n",
        "\n",
        "# Save raw QuickDraw data for backup\n",
        "np.save(os.path.join(RAW_DATA_DIR, \"quickdraw_raw.npy\"), quickdraw_data)"
      ],
      "metadata": {
        "id": "yd-sF_G1bqun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load new processed images\n",
        "def load_new_images(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(),\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    for idx, cls in enumerate(CLASSES):\n",
        "        class_dir = os.path.join(data_dir, cls)\n",
        "        if os.path.exists(class_dir):\n",
        "            for img_file in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, img_file)\n",
        "                try:\n",
        "                    image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
        "                    image = transform(image)\n",
        "                    images.append(image.squeeze(0).numpy())  # Remove extra channel\n",
        "                    labels.append(idx)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {img_file}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "VlYG9xWEbtbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new processed dataset\n",
        "new_images, new_labels = load_new_images(NEW_DATA_DIR)"
      ],
      "metadata": {
        "id": "LSQBu5fkbzh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert QuickDraw data to numpy arrays\n",
        "quickdraw_images = []\n",
        "quickdraw_labels = []\n",
        "\n",
        "for idx, cls in enumerate(CLASSES):\n",
        "    images = quickdraw_data[cls].reshape(-1, 28, 28)  # Reshape for consistency\n",
        "    quickdraw_images.append(images)\n",
        "    quickdraw_labels.extend([idx] * len(images))\n",
        "\n",
        "quickdraw_images = np.vstack(quickdraw_images)  # Stack into one array\n",
        "quickdraw_labels = np.array(quickdraw_labels)"
      ],
      "metadata": {
        "id": "j6-hKP4Cb1ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine QuickDraw and new processed images\n",
        "combined_images = np.concatenate((quickdraw_images, new_images))\n",
        "combined_labels = np.concatenate((quickdraw_labels, new_labels))"
      ],
      "metadata": {
        "id": "C_Dhb-Vzb5zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total dataset size: {len(combined_images)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eekt4bUib-dx",
        "outputId": "cac3fa1e-6fda-4a2f-a50a-4825456da3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 5463 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into Train (60%), Val (20%), Test (20%)\n",
        "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
        "    combined_images, combined_labels, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    temp_images, temp_labels, test_size=0.5, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "7z5wrtP2eoIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset in .npy format\n",
        "np.save(os.path.join(OUTPUT_DIR, \"train_images.npy\"), train_images)\n",
        "np.save(os.path.join(OUTPUT_DIR, \"train_labels.npy\"), train_labels)\n",
        "np.save(os.path.join(OUTPUT_DIR, \"val_images.npy\"), val_images)\n",
        "np.save(os.path.join(OUTPUT_DIR, \"val_labels.npy\"), val_labels)\n",
        "np.save(os.path.join(OUTPUT_DIR, \"test_images.npy\"), test_images)\n",
        "np.save(os.path.join(OUTPUT_DIR, \"test_labels.npy\"), test_labels)\n",
        "\n",
        "print(f\"Train size: {len(train_images)}, Val size: {len(val_images)}, Test size: {len(test_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpbo5r1neuZM",
        "outputId": "f0a28b51-3da8-4697-fa35-4514348584e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 3277, Val size: 1093, Test size: 1093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TymF2z_bf0W3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}